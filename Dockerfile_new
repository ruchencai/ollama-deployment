FROM --platform=linux/amd64 python:3.11-slim

# Install system dependencies with better error handling
RUN apt-get update && apt-get install -y \
    curl \
    procps \
    ca-certificates \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/* \
    && rm -rf /tmp/* \
    && rm -rf /var/tmp/*

WORKDIR /app

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Install Ollama with error handling
RUN curl -fsSL https://ollama.ai/install.sh | sh || \
    (echo "Ollama install failed, trying alternative..." && \
     curl -L https://ollama.ai/download/ollama-linux-amd64 -o /usr/local/bin/ollama && \
     chmod +x /usr/local/bin/ollama)

# Copy application code
COPY app.py .

# Create robust startup script
RUN echo '#!/bin/bash\n\
set -e\n\
\n\
echo "=== Starting Ollama server ==="\n\
ollama serve &\n\
OLLAMA_PID=$!\n\
\n\
echo "=== Waiting for Ollama to be ready ==="\n\
for i in {1..60}; do\n\
    if curl -s http://localhost:11434/api/tags >/dev/null 2>&1; then\n\
        echo "✅ Ollama is ready!"\n\
        break\n\
    fi\n\
    echo "⏳ Waiting for Ollama... ($i/60)"\n\
    sleep 2\n\
done\n\
\n\
echo "=== Starting FastAPI application ==="\n\
export PYTHONUNBUFFERED=1\n\
exec python -u app.py\n\
' > start.sh && chmod +x start.sh

EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=30s --start-period=300s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

CMD ["./start.sh"]
